{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BcY5_Ockl46"
      },
      "source": [
        "# Recommendation Systems Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "235bWFAekl48"
      },
      "source": [
        "### MIE451/1513 UofT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCfnJr0kkl49"
      },
      "source": [
        "### Getting MovieLens data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXsaip10kl49"
      },
      "source": [
        "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
        "\n",
        "* Upload ml-100k.zip\n",
        "\n",
        "* Extract using the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-iq33mHkl4-"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-q5GSoGkl4_"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wget\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lApqVGHkl5D"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYKNkW1RlRo7"
      },
      "outputs": [],
      "source": [
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o16EuZzkl5E"
      },
      "outputs": [],
      "source": [
        "!unzip ml-100k.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar-7dBwWkl5H"
      },
      "outputs": [],
      "source": [
        "MOVIELENS_DIR = \"ml-100k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x44yczpQkl5J"
      },
      "outputs": [],
      "source": [
        "!ls {MOVIELENS_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzn9YHZ5kl5N"
      },
      "outputs": [],
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPPv7a64kl5P"
      },
      "outputs": [],
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDhi48kfpmIM"
      },
      "outputs": [],
      "source": [
        "rating_df_train = getData(MOVIELENS_DIR, 'u1.base')\n",
        "rating_df_test = getData(MOVIELENS_DIR, 'u1.test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHuQ8mdgkl5U"
      },
      "outputs": [],
      "source": [
        "rating_df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KkT7cAClfgX"
      },
      "outputs": [],
      "source": [
        "rating_df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2xnIKPhpu5B"
      },
      "outputs": [],
      "source": [
        "print(\"Number of users in rating df:\", len(rating_df.userID.unique()))\n",
        "print(\"Number of items in rating df:\", len(rating_df.itemID.unique()))\n",
        "print(\"Number of users in train df:\", len(rating_df_train.userID.unique()))\n",
        "print(\"Number of items in train df:\", len(rating_df_train.itemID.unique()))\n",
        "print(\"Number of users in test df:\", len(rating_df_test.userID.unique()))\n",
        "print(\"Number of items in test df:\", len(rating_df_test.itemID.unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR7vdiHXkl5X"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr20553Xkl5Y"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILviGhqmkl5Y"
      },
      "outputs": [],
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT:\n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "\n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array.\n",
        "\n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'\n",
        "\n",
        "        NOTE 2: data can have more columns, but your function should ignore\n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "\n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGbDqRh2kl5b"
      },
      "outputs": [],
      "source": [
        "a = dataPreprocessor(rating_df,  len(rating_df.userID.unique()),  len(rating_df.itemID.unique()))\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXqyhOfFkl5d"
      },
      "outputs": [],
      "source": [
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            method: string. From ['popularity','useraverage']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.method_name\n",
        "\n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "\n",
        "        return switcher[method_name]\n",
        "\n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "\n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'\n",
        "        \"\"\"\n",
        "\n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "\n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "\n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'\n",
        "        \"\"\"\n",
        "\n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "\n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        self.__model = self.method(train_matrix, num_users, num_items)\n",
        "\n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "\n",
        "        for (index,\n",
        "             userID,\n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "\n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.__model = None\n",
        "        except:\n",
        "            print(\"You don not have model..\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zurYAYyjkl5f"
      },
      "outputs": [],
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sHa0zXlkl5i"
      },
      "outputs": [],
      "source": [
        "popularity_recsys.predict_all(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giq5zqr7kl5k"
      },
      "outputs": [],
      "source": [
        "x = popularity_recsys.getModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBbIYi3hkl5m"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wi14ORbkl5p"
      },
      "outputs": [],
      "source": [
        "np.all(x<=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miqyE7Njkl5r"
      },
      "outputs": [],
      "source": [
        "rating_df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcrT2iZHkl5t"
      },
      "outputs": [],
      "source": [
        "popularity_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJmmBimakl5x"
      },
      "outputs": [],
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GimZG_I5kl5z"
      },
      "outputs": [],
      "source": [
        "average_user_rating_recsys.predict_all(rating_df_train, len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q67CzhsPkl52"
      },
      "outputs": [],
      "source": [
        "average_user_rating_recsys.getModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnsQhlcvkl55"
      },
      "outputs": [],
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZfCb31Lkl57"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kXW-v4Gkl58"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYBLxL36kl59"
      },
      "outputs": [],
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "\n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "\n",
        "        return switcher[method_name]\n",
        "\n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "            cosine similarity\n",
        "        \"\"\"\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        return similarity_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "            euclidean similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "\n",
        "\n",
        "        ###########         end         ###########\n",
        "\n",
        "        return similarity_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "            manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return similarity_matrix\n",
        "\n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_row: scalar. number of users\n",
        "                num_col: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method assigns the result to self.__model\n",
        "\n",
        "            NOTES:\n",
        "                self.__model should contain predictions for *all* user and items\n",
        "                (don't worry about predicting for observed (user,item) pairs,\n",
        "                 since we won't be using these predictions in the evaluation)\n",
        "                (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "\n",
        "        if self.base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "\n",
        "            ###########         end         ###########\n",
        "\n",
        "        elif self.base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')\n",
        "\n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame.\n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "\n",
        "            NOTE: 1. data can have more columns, but your function should ignore\n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine',\n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "\n",
        "        for (index,\n",
        "             userID,\n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "\n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.__model = None\n",
        "        except:\n",
        "            print(\"You do not have model..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g9IyOZ_kl5_"
      },
      "outputs": [],
      "source": [
        "# Examples of how to call similarity functions.\n",
        "#I = np.eye(3)\n",
        "I = np.array([[3,0,2, 3],[0,5,3, 4], [3,3,5, 1], [0,5,0, 0], [3,5,0, 3]])\n",
        "print(I[[True,False, False, True, True]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnurO_C1kl6B"
      },
      "outputs": [],
      "source": [
        "SimBasedRecSys.cosine(I)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0t7XkANkl6E"
      },
      "outputs": [],
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eZkUZjUkl6G"
      },
      "outputs": [],
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jkhbA1skl6M"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRVfCtUtN92P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z8bQa-ssA6i"
      },
      "source": [
        "##Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNOujoIYsSxr"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nemy0aUsDki"
      },
      "outputs": [],
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaqHCcUnsGRk"
      },
      "outputs": [],
      "source": [
        "user_cosine_recsys.predict_all(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hZw9ZoFsH8q"
      },
      "outputs": [],
      "source": [
        "user_cosine_recsys.getModel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbOBbBRmsJwd"
      },
      "outputs": [],
      "source": [
        "rating_df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tVR1yCpsMXk"
      },
      "outputs": [],
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQvXdKtvvGC5"
      },
      "outputs": [],
      "source": [
        "item_cosine_recsys = SimBasedRecSys('item','cosine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuJEViXSvLQ0"
      },
      "outputs": [],
      "source": [
        "item_cosine_recsys.predict_all(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0v8pZ5dvQi-"
      },
      "outputs": [],
      "source": [
        "item_cosine_recsys.getModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2iYWj5wvVx3"
      },
      "outputs": [],
      "source": [
        "item_cosine_recsys.evaluate_test(rating_df_test,copy=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIz1L9AOsVBi"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNG6FQCDsVxq"
      },
      "outputs": [],
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "\n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "\n",
        "        return switcher[metric_name]\n",
        "\n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame.\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "\n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame.\n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "\n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame.\n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "\n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "\n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "\n",
        "        return matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "\n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms.\n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "\n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                display(prediction.head())\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "\n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "\n",
        "        results = scores\n",
        "\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qwtl3eulsy9o"
      },
      "outputs": [],
      "source": [
        "# How to use CrossValidation Class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7rKCHGhs1IL"
      },
      "outputs": [],
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [popularity_recsys,\n",
        "                       average_user_rating_recsys,\n",
        "                       user_cosine_recsys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlPQWUjjs5GC"
      },
      "outputs": [],
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, RPrecision\n",
        "# Precision at K in this example\n",
        "cv_patk = CrossValidation('P@K')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnfTUYwbs731"
      },
      "outputs": [],
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "cv_patk.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()),k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zuuPq3otAKN"
      },
      "source": [
        "##Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBUweLBRtUtv"
      },
      "source": [
        "(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2up92VkffEpj"
      },
      "source": [
        "## PMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__FGWLJukl8p"
      },
      "outputs": [],
      "source": [
        "class PMFRecSys(object):\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "            num_feat: int, number of latent features\n",
        "            epsilon: float, learning rate\n",
        "            _lambda: float, L2 regularization,\n",
        "            momentum: float, momentum of the gradient,\n",
        "            maxepoch: float, Number of epoch before stop,\n",
        "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
        "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
        "\n",
        "        \"\"\"\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "\n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.pred_column_name='PMF'\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_user: scalar. number of users\n",
        "                num_item: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method update w_User and w_Item\n",
        "\n",
        "            NOTES:\n",
        "                self.W_Item and self.W_User are use to do the final predition for a user\n",
        "\n",
        "        \"\"\"\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "\n",
        "        train_vec = train_vec.iloc[:, :3].values\n",
        "        if self.test:\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0]\n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "\n",
        "\n",
        "        # to avoid out of bound\n",
        "        num_user += 1\n",
        "        num_item += 1\n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        ########### your code goes here ###########\n",
        "        self.w_Item = None\n",
        "        self.w_User = None\n",
        "        ###########         end         ###########\n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch:\n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])\n",
        "            np.random.shuffle(shuffled_order)  #shuffled\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches):\n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
        "\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
        "\n",
        "\n",
        "                # Compute mean rating subtracted rating\n",
        "                ########### your code goes here ###########\n",
        "                pred_out = None #size (batch_size, )\n",
        "\n",
        "\n",
        "                ###########         end         ###########\n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :]\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat))\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc\n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating\n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "\n",
        "                    # Compute Compute mean rating subtracted rating\n",
        "                    ########### your code goes here ###########\n",
        "                    pred_out = None # size(pairs_train, )\n",
        "\n",
        "\n",
        "                    ###########         end         ###########\n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2]\n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "\n",
        "                    # Compute Compute mean rating subtracted rating\n",
        "                    ########### your code goes here ###########\n",
        "                    pred_out = pred_out = None #size(pairs_val, )\n",
        "\n",
        "\n",
        "                    ###########         end         ###########\n",
        "\n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame.\n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "\n",
        "            NOTE: 1. data can have more columns, but your function should ignore\n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine',\n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "\n",
        "        for (index,\n",
        "             userID,\n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def plot_error(self):\n",
        "      if self.test:\n",
        "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
        "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
        "      plt.title('The MovieLens Dataset Learning Curve')\n",
        "      plt.xlabel('Number of Epochs')\n",
        "      plt.ylabel('RMSE')\n",
        "      plt.legend()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "\n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.w_Item = None\n",
        "            self.w_User = None\n",
        "        except:\n",
        "            print(\"You do not have w_Item, w_User\")\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)\n",
        "        else:\n",
        "          raise Exception(\"You need to pass in a dictionary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUq2Ii8VFrlc"
      },
      "outputs": [],
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 100, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oGaU1GnuWs4"
      },
      "outputs": [],
      "source": [
        "pmf.predict_all(rating_df,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
        "pmf.plot_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89cEJ16G7LX"
      },
      "source": [
        "##Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2vy8i_-Q1E1"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1zy6eHOQtL3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZqmO6JDQ3Cp"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUmVr6baQ5Cu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzxlnKuUQ-Wv"
      },
      "source": [
        "### (c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eybKbo00Q_WQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5erVTiOQ_n6"
      },
      "source": [
        "### (d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x7Q_NSmRAtn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mpUBO7Hkl7G"
      },
      "source": [
        "## Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPZ0GoWPkl7G"
      },
      "source": [
        "\n",
        "\n",
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSmTou9rRItV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-upT6yRNkl7T"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SR6caHCRI_s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzPwzr6Fkl7U"
      },
      "source": [
        "## Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAXQWZT7kl7V"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3yqENAGUm2E"
      },
      "outputs": [],
      "source": [
        "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
        "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
        "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
        "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ghvdgr_9Tya"
      },
      "outputs": [],
      "source": [
        "def plot_embs_one_genre(embeddings, moviesDF, genre, sample_size):\n",
        "  \"\"\"\n",
        "            INPUT:\n",
        "                embeddings: numpy Array\n",
        "                moviesDF: pandas DataFrame.\n",
        "                          columns=['movieID',\t'movieTitle',\t'releaseDate\tvideo','ReleaseDate',\t'IMDbURL',...]\n",
        "                genre: string. (e.g., 'action', 'comedy', etc.)\n",
        "                sample_size: int\n",
        "\n",
        "\n",
        "            OUTPUT:\n",
        "                None\n",
        "\n",
        "            NOTE: 1. You can read the file 'u.item' into a pandaas DataFrame for using as moviesDF\n",
        "  \"\"\"\n",
        "  np.random.seed(3)\n",
        "  genre1_movie_ids = np.random.choice(moviesDF[moviesDF[genre] == 1]['movieID'].values, size = sample_size, replace=False)\n",
        "  genre1_embeddings = embeddings[genre1_movie_ids]\n",
        "\n",
        "  genre2_movie_ids = np.random.choice(moviesDF[moviesDF[genre] == 0]['movieID'].values, size = sample_size, replace=False)\n",
        "  genre2_embeddings = embeddings[genre2_movie_ids]\n",
        "\n",
        "  all_ids = np.concatenate([genre1_movie_ids, genre2_movie_ids])\n",
        "  index2id = {i:all_ids[i] for i in range(all_ids.shape[0])}\n",
        "\n",
        "  all_embeddings = embeddings[all_ids]\n",
        "\n",
        "\n",
        "  top_indices = np.argpartition(all_embeddings, -3, axis=0)[-3:]\n",
        "\n",
        "  bottom_indices = np.argpartition(all_embeddings, 3, axis=0)[:3]\n",
        "\n",
        "  v_offset = 20\n",
        "\n",
        "  for i in range(embeddings.shape[1]):\n",
        "    plt.close()\n",
        "    plt.figure()\n",
        "    plt.scatter(genre1_embeddings[:, i], np.full_like(genre1_movie_ids, i), c='red', label=f'{genre}')\n",
        "    plt.scatter(genre2_embeddings[:, i], np.full_like(genre2_movie_ids, i), c='blue', label=f'not {genre}')\n",
        "\n",
        "    for k, j in enumerate(top_indices[:, i]):\n",
        "      y_offset = k * v_offset\n",
        "      plt.annotate(moviesDF.loc[moviesDF['movieID'] == index2id[j], 'movieTitle'].values[0], (all_embeddings[j, i], i ), xytext=(-2*y_offset, 20+i+y_offset), textcoords='offset points', fontsize=8, color='black', arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.3' ,color='black'))\n",
        "\n",
        "    for k, j in enumerate(bottom_indices[:, i]):\n",
        "      y_offset = k * v_offset\n",
        "      plt.annotate(moviesDF.loc[moviesDF['movieID'] == index2id[j], 'movieTitle'].values[0], (all_embeddings[j, i], i), xytext=(2*y_offset, -20-i-y_offset), textcoords='offset points', fontsize=8, color='black', arrowprops=dict(arrowstyle='->',connectionstyle='arc3,rad=0.3', color='black'))\n",
        "\n",
        "    plt.xlabel('Embedding Value')\n",
        "    plt.ylabel('Movie ID')\n",
        "    plt.legend()\n",
        "    plt.title(f'Dimension {i} Embeddings for {genre} and not {genre} Movies')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flTS99pHSPjL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgjeqGCi-b3r"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUjskarHJXly"
      },
      "outputs": [],
      "source": [
        "def plot_embs_two_genres(embeddings, moviesDF, genres, sample_size):\n",
        "  \"\"\"\n",
        "            INPUT:\n",
        "                embeddings: numpy Array\n",
        "                moviesDF: pandas DataFrame.\n",
        "                          columns=['movieID',\t'movieTitle',\t'releaseDate\tvideo','ReleaseDate',\t'IMDbURL',...]\n",
        "                genres: list of strings. (e.g., ['action', 'comedy'])\n",
        "                sample_size: int\n",
        "\n",
        "\n",
        "            OUTPUT:\n",
        "                None\n",
        "\n",
        "            NOTE: 1. You can read the file 'u.item' into a pandaas DataFrame for using as moviesDF\n",
        "  \"\"\"\n",
        "\n",
        "  genre1 = genres[0]\n",
        "  genre2 = genres[1]\n",
        "  np.random.seed(3)\n",
        "  genre1_movie_ids = np.random.choice(moviesDF[moviesDF[genre1] == 1]['movieID'].values, size = sample_size, replace=False)\n",
        "  genre1_embeddings = embeddings[genre1_movie_ids]\n",
        "\n",
        "  genre2_movie_ids = np.random.choice(moviesDF[moviesDF[genre2] == 1]['movieID'].values, size = sample_size, replace=False)\n",
        "  genre2_embeddings = embeddings[genre2_movie_ids]\n",
        "\n",
        "  all_ids = np.concatenate([genre1_movie_ids, genre2_movie_ids])\n",
        "  index2id = {i:all_ids[i] for i in range(all_ids.shape[0])}\n",
        "\n",
        "  all_embeddings = embeddings[all_ids]\n",
        "\n",
        "\n",
        "  top_indices = np.argpartition(all_embeddings, -3, axis=0)[-3:]\n",
        "\n",
        "  bottom_indices = np.argpartition(all_embeddings, 3, axis=0)[:3]\n",
        "\n",
        "  v_offset = 20\n",
        "\n",
        "  for i in range(embeddings.shape[1]):\n",
        "    plt.close()\n",
        "    plt.figure()\n",
        "    plt.scatter(genre1_embeddings[:, i], np.full_like(genre1_movie_ids, i), c='red', label=f'{genre1}')\n",
        "    plt.scatter(genre2_embeddings[:, i], np.full_like(genre2_movie_ids, i), c='blue', label=f'{genre2}')\n",
        "\n",
        "    for k, j in enumerate(top_indices[:, i]):\n",
        "      y_offset = k * v_offset\n",
        "      plt.annotate(moviesDF.loc[moviesDF['movieID'] == index2id[j], 'movieTitle'].values[0], (all_embeddings[j, i], i ), xytext=(-2*y_offset, 20+i+y_offset), textcoords='offset points', fontsize=8, color='black', arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.3' ,color='black'))\n",
        "\n",
        "    for k, j in enumerate(bottom_indices[:, i]):\n",
        "      y_offset = k * v_offset\n",
        "      plt.annotate(moviesDF.loc[moviesDF['movieID'] == index2id[j], 'movieTitle'].values[0], (all_embeddings[j, i], i), xytext=(2*y_offset, -20-i-y_offset), textcoords='offset points', fontsize=8, color='black', arrowprops=dict(arrowstyle='->',connectionstyle='arc3,rad=0.3', color='black'))\n",
        "\n",
        "    plt.xlabel('Embedding Value')\n",
        "    plt.ylabel('Movie ID')\n",
        "    plt.legend()\n",
        "    plt.title(f'Dimension {i} Embeddings for {genre1} and {genre2} Movies')\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdmvmnKkSQPh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O195ougPJXjm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S1XDaOvsqAe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHljZzhIN3nF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-3s7koh7kl79"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSH2Bc_Ikl79"
      },
      "outputs": [],
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1CzSVkckl7_"
      },
      "source": [
        "### dataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFfeF5-ikl7_"
      },
      "outputs": [],
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWvTLz24kl8A"
      },
      "outputs": [],
      "source": [
        "validation_df = validateDataPreprocessor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTH-B8PTkl8D"
      },
      "source": [
        "## Baseline Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxDRe7o1kl8E"
      },
      "source": [
        "### Popularity Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_-tbIfrkl8F"
      },
      "outputs": [],
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3HbCXrGkl8H"
      },
      "outputs": [],
      "source": [
        "validatePopularityRecSys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQAsgp7Gkl8K"
      },
      "source": [
        "### User Average Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjZ9JCS2kl8L"
      },
      "outputs": [],
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    #useraverage_recsys = BaseLineRecSys('average_user_rating')\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRCaH7OOkl8M"
      },
      "outputs": [],
      "source": [
        "validateUserAverRecSys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qppYkpp4kl8P"
      },
      "source": [
        "## Similary Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVOLboYRkl8P"
      },
      "source": [
        "### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw7lSsCWkl8Q"
      },
      "outputs": [],
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMuw3Z8Ekl8V"
      },
      "outputs": [],
      "source": [
        "validateEuclidean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPNO18eSkl8X"
      },
      "source": [
        "### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9U-rA0IJkl8a"
      },
      "outputs": [],
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHVAc_5Qkl8c"
      },
      "outputs": [],
      "source": [
        "validateCustomizedSim()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG6lm_Otkl8e"
      },
      "source": [
        "### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zieqs8oFkl8e"
      },
      "outputs": [],
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Framework error, please make sure you are using given yml file.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8A8_2Chkl8g"
      },
      "outputs": [],
      "source": [
        "validateUUSimBasedRecSys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAlHvDSkl8h"
      },
      "source": [
        "### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8heph2tokl8i"
      },
      "outputs": [],
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Framework error, please make sure you are using given yml file.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_BJVmG4kl8j"
      },
      "outputs": [],
      "source": [
        "validateIISimBasedRecSys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhebOs0tDWTK"
      },
      "outputs": [],
      "source": [
        "def validatePMFRecSys(validation_df=validation_df):\n",
        "    try:\n",
        "        pmf = PMFRecSys()\n",
        "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
        "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
        "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOnXlmRLDZhQ"
      },
      "outputs": [],
      "source": [
        "validatePMFRecSys(validation_df=validation_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2y_G7ZXsY7n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
